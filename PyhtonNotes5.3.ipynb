{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert video into text of audio\n",
    "video --> audio --> text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting SpeechRecognition\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/54/82f70dd84a89ce66b8431338a14fc8580e825e39ca5d79775859f2bcf895/SpeechRecognition-3.9.0-py2.py3-none-any.whl (32.8MB)\n",
      "\u001b[K     |████████████████████████████████| 32.8MB 15.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting moviepy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/54/01a8c4e35c75ca9724d19a7e4de9dc23f0ceb8769102c7de056113af61c3/moviepy-1.0.3.tar.gz (388kB)\n",
      "\u001b[K     |████████████████████████████████| 389kB 58.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=2.26.0 (from SpeechRecognition)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/f4/274d1dbe96b41cf4e0efb70cbced278ffd61b5c7bb70338b62af94ccb25b/requests-2.28.2-py3-none-any.whl (62kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 39.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator<5.0,>=4.0.2 in /opt/conda/lib/python3.7/site-packages (from moviepy) (4.4.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.7/site-packages (from moviepy) (4.32.2)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading https://files.pythonhosted.org/packages/8b/f5/cab5cf6a540c31f5099043de0ae43990fd9cf66f75ecb5e9f254a4e4d4ee/proglog-0.1.10-py3-none-any.whl\n",
      "Collecting numpy>=1.17.3 (from moviepy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/ad/ff3b21ebfe79a4d25b4a4f8e5cf9fd44a204adb6b33c09010f566f51027a/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7MB)\n",
      "\u001b[K     |████████████████████████████████| 15.7MB 51.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.7/site-packages (from moviepy) (2.5.0)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/3f/fc9a0345a0ef2d9596c3d3d9549ac72377ea97c289abcf3c96f0821c3072/imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9MB)\n",
      "\u001b[K     |████████████████████████████████| 26.9MB 51.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.26.0->SpeechRecognition) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.26.0->SpeechRecognition) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.26.0->SpeechRecognition) (1.25.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.26.0->SpeechRecognition) (2.8)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from imageio<3.0,>=2.5->moviepy) (6.1.0)\n",
      "Building wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-cp37-none-any.whl size=110729 sha256=f8a605ebc8b5cfc73841dd6259eff0b83354078c7db52b9edc241d31e079724a\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e0/fe/1c/f4e6dca9e828d4b979c04e461d7fcc5b8e7bd35f947e665b65\n",
      "Successfully built moviepy\n",
      "\u001b[31mERROR: tensorboard 2.1.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.16.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: requests, SpeechRecognition, proglog, numpy, imageio-ffmpeg, moviepy\n",
      "  Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Found existing installation: numpy 1.16.0\n",
      "    Uninstalling numpy-1.16.0:\n",
      "      Successfully uninstalled numpy-1.16.0\n",
      "Successfully installed SpeechRecognition-3.9.0 imageio-ffmpeg-0.4.8 moviepy-1.0.3 numpy-1.21.6 proglog-0.1.10 requests-2.28.2\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in converted.wav\n",
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "clip = mp.VideoFileClip(r\"ErnestoSample.mp4\")\n",
    "clip.audio.write_audiofile(r\"converted.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer() #creates recognizer file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = sr.AudioFile('converted.wav') #assigns audio as variable for audio in video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.97036517,\n",
      "                           'transcript': 'hello my name is Ernesto Lee from '\n",
      "                                         'nesto.tv and ernesto.net and in this '\n",
      "                                         \"very important episode I'm going to \"\n",
      "                                         'show you the math behind machine '\n",
      "                                         'learning and deep learning I '\n",
      "                                         'typically like to stay away from the '\n",
      "                                         'math because I feel sometimes that '\n",
      "                                         'is intimidating to students and it '\n",
      "                                         'turns a lot of people'},\n",
      "                       {   'transcript': 'hello my name is Ernesto Lee from '\n",
      "                                         'nesto.tv and ernesto.net and in this '\n",
      "                                         \"very important episode I'm going to \"\n",
      "                                         'show you the math behind machine '\n",
      "                                         'learning and deep learning I '\n",
      "                                         'typically like to stay away from the '\n",
      "                                         'map because I feel sometimes that is '\n",
      "                                         'intimidating to students and it '\n",
      "                                         'turns a lot of people'}],\n",
      "    'final': True}\n"
     ]
    }
   ],
   "source": [
    "with audio as source:\n",
    "    audio_file = r.record(source)\n",
    "result = r.recognize_google(audio_file) #runs the speach recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready!\n"
     ]
    }
   ],
   "source": [
    "with open('recognized.txt', mode='w') as file:\n",
    "    file.write(\"This is the recognized speech in the video: \")\n",
    "    file.write(\"\\n\")\n",
    "    file.write(result)\n",
    "    print(\"ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-bf9_5d0d\n",
      "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-bf9_5d0d\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from openai-whisper==20230124) (1.21.6)\n",
      "Collecting torch (from openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/86/77a9eddbf46f1bca2468d16a401911f58917f95b63402d6a7a4522521e5d/torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5MB)\n",
      "\u001b[K     |████████████████████████████████| 887.5MB 39kB/s s eta 0:00:01     |█████████▏                      | 254.0MB 70.9MB/s eta 0:00:09     |██████████████████▏             | 503.7MB 51.5MB/s eta 0:00:08     |███████████████████████         | 640.8MB 58.7MB/s eta 0:00:05     |██████████████████████████▎     | 727.7MB 73.5MB/s eta 0:00:03     |██████████████████████████████▎ | 840.8MB 61.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai-whisper==20230124) (4.32.2)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.7/site-packages (from openai-whisper==20230124) (8.0.2)\n",
      "Collecting transformers>=4.19.0 (from openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/1a/ef470ac1ff879b823c718ddc08c5b33ab4e68100b565a7037f8bf3aa98de/transformers-4.26.0-py3-none-any.whl (6.3MB)\n",
      "\u001b[K     |████████████████████████████████| 6.3MB 47.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ffmpeg-python==0.2.0 (from openai-whisper==20230124)\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" (from torch->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/41/fdeb62b5437996e841d83d7d2714ca75b886547ee8017ee2fe6ea409d983/nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1MB)\n",
      "\u001b[K     |████████████████████████████████| 317.1MB 8.1MB/s eta 0:00:011     |███████████████████▎            | 191.2MB 66.8MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" (from torch->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/92/89cf558b514125d2ebd8344dd2f0533404b416486ff681d5434a5832a019/nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849kB)\n",
      "\u001b[K     |████████████████████████████████| 849kB 48.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" (from torch->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/25/922c5996aada6611b79b53985af7999fc629aee1d5d001b6a22431e18fec/nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0MB 46.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" (from torch->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/30/66d4347d6e864334da5bb1c7571305e501dcb11b9155971421bb7bb5315f/nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1MB)\n",
      "\u001b[K     |████████████████████████████████| 557.1MB 58kB/s s eta 0:00:01     |███████████████████████▏        | 402.4MB 8.3MB/s eta 0:00:19     |████████████████████████████    | 487.4MB 58.9MB/s eta 0:00:02     |█████████████████████████████▎  | 509.5MB 5.0MB/s eta 0:00:10     |███████████████████████████████ | 539.7MB 5.0MB/s eta 0:00:04     |███████████████████████████████▏| 541.7MB 5.0MB/s eta 0:00:04     |███████████████████████████████▌| 547.6MB 50.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->openai-whisper==20230124) (4.4.0)\n",
      "Collecting packaging>=20.0 (from transformers>=4.19.0->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/35/a31aed2993e398f6b09a790a181a7927eb14610ee8bbf02dc14d31677f1c/packaging-23.0-py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 35.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->openai-whisper==20230124) (1.3.0)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers>=4.19.0->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/0b/e4c1165bb954036551e61e1d7858e3293347f360d8f84854092f3ad38446/huggingface_hub-0.11.1-py3-none-any.whl (182kB)\n",
      "\u001b[K     |██████████████████████████████▌ | 174kB 66.8MB/s eta 0:00:01█████████| 184kB 66.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.28.2)\n",
      "Collecting filelock (from transformers>=4.19.0->openai-whisper==20230124)\n",
      "  Downloading https://files.pythonhosted.org/packages/14/4c/b201d0292ca4e0950f0741212935eac9996f69cd66b92a3587e594999163/filelock-3.9.0-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->openai-whisper==20230124) (5.1.2)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.19.0->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/f2/20be658beb9ebef677550be562eae86c5433119b4b2fdb67035e9a841b0f/regex-2022.10.31-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (676kB)\n",
      "\u001b[K     |████████████████████████████████| 686kB 52.6MB/s eta 0:00:01           | 225kB 52.6MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.19.0->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/d9/af2821b5934ed871f716eb65fb3bd43e7bc70b99191ec08f20cfd642d0a1/tokenizers-0.13.2.tar.gz (359kB)\n",
      "\u001b[K     |████████████████████████████████| 368kB 33.8MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.18.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"->torch->openai-whisper==20230124) (41.0.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"->torch->openai-whisper==20230124) (0.33.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=4.19.0->openai-whisper==20230124) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.25.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2019.11.28)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (PEP 517) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python /opt/conda/lib/python3.7/site-packages/pip/_vendor/pep517/_in_process.py build_wheel /tmp/tmp09emi2xp\n",
      "       cwd: /tmp/pip-install-2xodamg7/tokenizers\n",
      "  Complete output (51 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-cpython-37\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers\n",
      "  copying py_src/tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/models\n",
      "  copying py_src/tokenizers/models/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/models\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/decoders\n",
      "  copying py_src/tokenizers/decoders/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/decoders\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/normalizers\n",
      "  copying py_src/tokenizers/normalizers/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/normalizers\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/pre_tokenizers\n",
      "  copying py_src/tokenizers/pre_tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/pre_tokenizers\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/processors\n",
      "  copying py_src/tokenizers/processors/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/processors\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/trainers\n",
      "  copying py_src/tokenizers/trainers/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/trainers\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/sentencepiece_bpe.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/sentencepiece_unigram.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/base_tokenizer.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/char_level_bpe.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/byte_level_bpe.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/bert_wordpiece.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/tools\n",
      "  copying py_src/tokenizers/tools/visualizer.py -> build/lib.linux-x86_64-cpython-37/tokenizers/tools\n",
      "  copying py_src/tokenizers/tools/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/tools\n",
      "  copying py_src/tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers\n",
      "  copying py_src/tokenizers/models/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers/models\n",
      "  copying py_src/tokenizers/decoders/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers/decoders\n",
      "  copying py_src/tokenizers/normalizers/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers/normalizers\n",
      "  copying py_src/tokenizers/pre_tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers/pre_tokenizers\n",
      "  copying py_src/tokenizers/processors/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers/processors\n",
      "  copying py_src/tokenizers/trainers/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers/trainers\n",
      "  copying py_src/tokenizers/tools/visualizer-styles.css -> build/lib.linux-x86_64-cpython-37/tokenizers/tools\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for tokenizers\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-2xodamg7/tokenizers/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-2xodamg7/tokenizers/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' clean --all\n",
      "       cwd: /tmp/pip-install-2xodamg7/tokenizers\n",
      "  Complete output (17 lines):\n",
      "  running clean\n",
      "  removing 'build/lib.linux-x86_64-cpython-37' (and everything under it)\n",
      "  'build/bdist.linux-x86_64' does not exist -- can't clean it\n",
      "  'build/scripts-3.7' does not exist -- can't clean it\n",
      "  removing 'build'\n",
      "  running clean_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed cleaning build dir for tokenizers\u001b[0m\n",
      "Failed to build tokenizers\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230124-cp37-none-any.whl size=1179323 sha256=a040b64cf9bc97e09ec2bff76ea9183f9a604517fbfb69170f255635ad629784\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-erxjkoo2/wheels/f7/a2/f4/4fcc21ffab3471a668533ce9a7fcf9dc13ec2540ed6cec230c\n",
      "Successfully built openai-whisper\n",
      "\u001b[31mERROR: Could not build wheels for tokenizers which use PEP 517 and cannot be installed directly\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting pytube\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/61/d53566d4634f3f27b60867f054330b3ec1d22d399e20a9708a1a00471987/pytube-12.1.2-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 18.4MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pytube\n",
      "Successfully installed pytube-12.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install pytube\n",
    "# well this didn't work but open whisper is 'unparralled' -Dr. Lee. will probably get working tomorrow\n",
    "# See Dr. Lee Whisper google colab for working example vv\n",
    "# https://colab.research.google.com/drive/1l5cTBLBqoi61Btk1D-ZdwZOIKJ3nn4Zv?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
